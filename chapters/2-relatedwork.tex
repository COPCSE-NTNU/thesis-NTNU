\chapter{Related Work}
\label{chap:relwork}

\section{Effects of Cybersecurity Incidents}
Due to the lack of self-reporting, data regarding incidents are difficult to obtain. Such incidents by their nature can be expected to have a negative short term impact on the stock price. This means that executives and decision-makers in companies are incentivised to not publicise incidents. Because they are often compensated based on stock performance. On the other hand, laws such as General Data Protection Regulation(GDPR) in the EU require the disclosure and notification if the incident affected personal/user data. On a similar note, most public stock exchanges require companies to disclose events of material impact on the company. However, given that there are few incentives to disclose such events one can expect companies to make a restrictive interpretation of what "material" means as to disclose as little as possible. 

One of the first studies into the effect of incidents was \textit{The economic cost of publicly announced information security breaches: empirical evidence from the stock market} by Campbell et. al.(2003)\cite{campbell2003economic}. They looked into the effect of incidents published in major newspapers(the paper kind). The researchers looked at events in the time-period 1995 to 2000. The total sample size obtained over the period was 43 events from 38 public companies. They looked at the price movement in a 3-day window surrounding the time of announcement. When looking at all the samples there was some slight indication of a negative reaction to incidents but not with a good p-value (p = 0.1393). When splitting the data and only looking at incidents involving unauthorised access to data. They found that the negative reaction was much more pronounced and of high significance. The authors suggests that the type of incident is of material importance with regard to the negative effect of the incident.

In the paper \textit{The effect of data breaches on shareholder wealth} by Gatzlaff and McCullough (2010)\cite{gatzlaff2010effect} they looked at the impact of incidents involving leakage of personal information. In total, the paper identified 77 events in the period 2004 to 2006 which was used in the study. They estimated the performance of a given stock relative to the market using a 1-year window before the incident, this was then compared to the performance of the stock up to 120 days after the incident became public. They found that the overall impact of disclosing such events are negative and that the result is statistically significant, with -0.84\% loss of company value. Furthermore, they also found that the negative effects can last for up to 40 days where performance returns to normal afterwards, additionally, they remark that growth stocks(higher book to value) are more affected than other types of stocks.

In the paper \textit{Do Firms Underreport Information on Cyber-Attacks? Evidence from Capital Markets.}\cite{amir2018firms} from 2018 Amir, Eli, et al. dug a bit deeper into the data and used it to estimate the likelihood of an incident being disclosed by the company itself. They manually combined and verified data from two sources and ended up with 276 samples from the period 2010 to 2015. Then they divided the data into self-disclosed and discovered by others. Then they categorized the data that was discovered by others into material and immaterial. They argue that the samples present in the material set should have been reported/disclosed by companies. While the immaterial set did not necessarily need to be disclosed. They show that the immaterial set does not affect the stock price meaningfully. Furthermore, they find that in the cases where a firm rapidly discloses the incident the value of the company drops by 0.33\% in the first 3 days and 0.72\% over the full month period after the breach. For the case where firms did not voluntarily disclose the incident but it was discovered by someone else, they find that the drop in value is 1.47\% and 3.56\% for the first 3 days and the full month respectively. Based on the data the authors suggest that managers are more likely to withhold severe incidents and that they only choose to disclose the incident when investors already suspect(with a 40\% confidence) that an incident has occurred. 

The newest and most comprehensive paper with regards to sample size is the paper \textit{A Comprehensive Analysis of Cyber Data Breaches and Their Resulting Effects on Shareholder Wealth} from 2020 by Hogan et al.\cite{hogan2020comprehensive}. They were able to obtain data regarding personal information leakage from a proprietary dataset from the insurance data provider Advisen Ltd. Advisen claim that the samples in their cyber loss data have been manually gathered and or verified. In total, the Adivsen cyber loss data yielded 3991 samples by far the largest of any known study. They also find that short term negative effects but not as pronounced as the other studies as some of the smaller earlier studies. Furthermore, they also find significant negative long term results with an average loss of -7.46\% with a p value < 0.0001, 250 trading days or about a year after the incident.

As we can see there exist several studies all concluding negative effects. However, all studies ultimately depend on manually gathered and/or proprietary data, and with the exception of Hogan et al.(2020) all studies use few samples.
\section{Text Classification}
There have been lots of work on machine learning models for text classification. In the last 10 years, there have been huge developments in the usage of deep learning models for this task. Rashid and O’Keefe explored Bidirectional Long
Short-Term Memory (BiLSTM) and Convolutional Neural Network (CNN) models\cite{pennington2014glove} in 2014 with promising results. Transformer models came out of a Google research by Vaswani et al. in 2017\cite{vaswani2017attention}, they represent a new type of machine learning model that does not rely on convolution and other recurrent mechanisms such as the ones used by ALRashdi and O’Keefe. The advantage of transformer models is the training speed which allows for larger models and the ingestion of more data. After the transformer google proposed The Bidirectional Encoder Representation of Transformer (BERT)\cite{devlin2018bert}. The idea behind BERT is that is pre-trained to connect bidirectional relations on unlabeled text. In theory, since human text/language transcends to lots of domains and applications, this can allow the pre-trained model to be deployed to many different scenarios with little additional training and to great effect. Another development in the field is the Generative Pre-trained Transformer(GPT) such as GPT-2\cite{radford2019language}. GPT models are like BERT models attention based transformers. There are some differences more specifically BERT is made up of transformer encoder blocks while GPT uses transformer decoder blocks. One of the major differences between the two is that GPT is auto-regressive. This means that each token(word) has the context of the previous tokens(words) when predicting text. This means that GPT operates one token at a time. BERT on the other hand operates on all the text at once. This means that when BERT is "learning" it has the context of the words ahead and behind(but it uses a dropout rate to limit the information available to the model), whereas GTP can only look behind but has the context of all the word behind the current token.

The proposed application of large transformer models together with the domain is novel territory. But transformers models like BERT and GPT have been shown to be highly effective across a wide range of applications. An example paper demonstrating is the CrisisBERT paper\cite{liu2021crisisbert}. In this paper, the researchers used BERT together with text from social media to identify crisis events with great accuracy. Other interesting papers with similar applications as proposed in this master's thesis is \textit{Detecting Hate Speech with GPT-3}\cite{chiu2021detecting} and \textit{GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain}\cite{moradi2021gpt}.
